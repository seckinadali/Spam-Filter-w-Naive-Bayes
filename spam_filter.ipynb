{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "511b2618-9218-4335-a417-8e5379f7f09b",
   "metadata": {},
   "source": [
    "# Building a Spam Filter Using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571f526-1637-4803-9778-bc0acad1a821",
   "metadata": {},
   "source": [
    "Our aim in this project is to build a spam filter for SMS messages using the multinomial naive Bayes classifier. At the end of this project we will have a program that classifies messages as spam or non-spam (ham) with an accuracy greater than 98%.\n",
    "\n",
    "In addition to implementing our own filter, we will look at `sklearn`'s multinomaial naive Bayes, random forest and support vector classifer models. We will compare the performances of all four using cross-validation.\n",
    "\n",
    "We are going to use a data set that contains 5,572 SMS messages that are already classified. The data set we will use, and more info on it, can be found on [the UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c468ba7-543c-4d87-9403-240435fa09ca",
   "metadata": {},
   "source": [
    "## Exploring the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef16b9ee-5cd6-47ec-ae62-c959bfa9c476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f3bff5-fe6e-478a-b273-3bc28151b729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms_label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sms_label                                        sms_message\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms = pd.read_csv('files/SMSSpamCollection', sep='\\t', header=None, names=['sms_label', 'sms_message'])\n",
    "\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b418e61-2faf-468b-99c4-45e41cb2d0e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67c44e2",
   "metadata": {},
   "source": [
    "Below we take a look at the distribution of the target and encode the target column in order to get it ready for ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d52de8-0371-4062-9d7e-30881f1864f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: sms_label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['sms_label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01517abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['sms_label'].replace({'spam':1, 'ham':0}, inplace=True)\n",
    "sms.rename(columns={'sms_label':'is_spam'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f3c5e-a025-46f2-80e3-69367d23a73f",
   "metadata": {},
   "source": [
    "## Forming Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608123d0",
   "metadata": {},
   "source": [
    "In order to check our filter, we'll initially use a simple pair of training and test sets; we'll separate the last fifth of our data set for testing. Later on, we'll move on to cross-validation for all models we consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361da746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spam                                        sms_message\n",
       "0        0                       Yep, by the pretty sculpture\n",
       "1        0      Yes, princess. Are you going to make me moan?\n",
       "2        0                         Welp apparently he retired\n",
       "3        0                                            Havent.\n",
       "4        0  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The index for splitting\n",
    "cutoff = round(len(sms) * 0.8)\n",
    "\n",
    "# Randomize the data set before splitting\n",
    "sms_randomized = sms.sample(frac=1, random_state=1)\n",
    "\n",
    "initial_training = sms_randomized[:cutoff].reset_index(drop=True)\n",
    "initial_test = sms_randomized[cutoff:].reset_index(drop=True)\n",
    "\n",
    "initial_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd019910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spam                                        sms_message\n",
       "0        0          Later i guess. I needa do mcat study too.\n",
       "1        0             But i haf enuff space got like 4 mb...\n",
       "2        1  Had your mobile 10 mths? Update to latest Oran...\n",
       "3        0  All sounds good. Fingers . Makes it difficult ...\n",
       "4        0  All done, all handed in. Don't know if mega sh..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a541381",
   "metadata": {},
   "source": [
    "Let's check whether the distributions of the target in these sets are similar to the whole data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4da89d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.86541\n",
       "1    0.13459\n",
       "Name: is_spam, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_training['is_spam'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d5d1652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.868043\n",
       "1    0.131957\n",
       "Name: is_spam, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_test['is_spam'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08138976-2c6c-4733-8c19-b3d0f6e15220",
   "metadata": {},
   "source": [
    "## Using Multinomial Naive Bayes\n",
    "\n",
    "Now we will start our calculations needed for the spam filter. We'll write three separate functions for our end goal:\n",
    "\n",
    "- `vectorize` will transform the training set to a matrix of token counts\n",
    "\n",
    "- `get_probs` will calculate the terms that recur for each word using the output of `vectorize`\n",
    "\n",
    "- `classify` will classify a message using the output of `get_probs`\n",
    "\n",
    "Recall that, given a message, the multinomial naive Bayes algorithm uses the following proportions to classify the message:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation*}\n",
    "\n",
    "Here, to calculate $P(w_i|Spam)$ and $P(w_i|Ham)$, we will use Laplace smoothing ($\\alpha = 1$).\n",
    "\n",
    "\\begin{equation*}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbccae6-4c7f-49ca-ab8f-78a986faa7e0",
   "metadata": {},
   "source": [
    "- We will start by calculating the terms that recur for each word, that is, the ones independent of $w_i$. These are $P(Spam)$, $P(Ham)$, $N_{Spam}$, $N_{Ham}$ and $N_{Vocabulary}$.\n",
    "\n",
    "- Next we will calculate the conditional probabilities for each word, namely $P(w_i|Spam)$ and $P(w_i|Ham)$. We will use separate dictionaries for the spam and ham cases.\n",
    "\n",
    "- Then we'll be ready to go ahead with the classification. Recall that the classifier compares the products $P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)$ and $P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cce51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(train):\n",
    "    '''train: subdataframe of sms\n",
    "    returns: vocabulay of train (list)\n",
    "    '''\n",
    "    cvec = CountVectorizer(ngram_range=(1, 1), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "\n",
    "    train_vec = cvec.fit_transform(train['sms_message'])\n",
    "\n",
    "    train_vectorized = pd.concat(\n",
    "        [train,\n",
    "         pd.DataFrame(train_vec.toarray(),\n",
    "                      columns=cvec.get_feature_names_out())],\n",
    "         axis=1\n",
    "    )\n",
    "\n",
    "    vocabulary = set(train_vectorized.columns) - {'sms_message', 'is_spam'}\n",
    "    return train_vectorized, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b1d366e-f371-4c7b-b856-4953097d4457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_probs(train, vocabulary):\n",
    "    '''Calculates probabilities using train as the training set\n",
    "\n",
    "    train: sub-dataframe of sms_vectorized\n",
    "    returns: cond_spam and cond_ham (dictionaries), p_spam and p_ham (floats)\n",
    "    '''\n",
    "    n_vocabulary = len(vocabulary)\n",
    "\n",
    "    alpha = 1 # Laplace smoothing\n",
    "\n",
    "    spam = train[train['is_spam'] == 1]\n",
    "    ham = train[train['is_spam'] == 0]\n",
    "\n",
    "    p_spam = len(spam) / len(train)\n",
    "    p_ham = len(ham) / len(train)\n",
    "\n",
    "    n_spam = spam['sms_message'].apply(len).sum()\n",
    "    n_ham = ham['sms_message'].apply(len).sum()\n",
    "\n",
    "    cond_spam, cond_ham = {}, {}\n",
    "\n",
    "    for w in vocabulary:\n",
    "        cond_spam[w] = (spam[w].sum() + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "        cond_ham[w] = (ham[w].sum() + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    \n",
    "    return p_spam, p_ham, cond_spam, cond_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed99656-509d-4df3-be70-50f425bcb88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify(sms, p_spam, p_ham, cond_spam, cond_ham, print_posterior=False):\n",
    "    '''CLassifies sms using train as the training set\n",
    "    \n",
    "    sms: (str) an sms message\n",
    "    train: sub-dataframe of sms_vectorized\n",
    "    returns: (str) classification of s\n",
    "    '''    \n",
    "    p_spam_given_sms = p_spam\n",
    "    p_ham_given_sms = p_ham\n",
    "    \n",
    "    for w in sms.split():\n",
    "        if w in cond_spam:\n",
    "            p_spam_given_sms *= cond_spam[w]\n",
    "        if w in cond_ham:\n",
    "            p_ham_given_sms *= cond_ham[w]\n",
    "    \n",
    "    if print_posterior:\n",
    "        print(\"SMS: \\\"{}\\\"\".format(sms))\n",
    "        print(\"P(Spam|SMS) = {}\".format(p_spam_given_sms))\n",
    "        print(\"P(Ham|SMS) = {}\".format(p_ham_given_sms))\n",
    "    \n",
    "    if p_spam_given_sms > p_ham_given_sms:\n",
    "        return 1\n",
    "    elif p_spam_given_sms < p_ham_given_sms:\n",
    "        return 0\n",
    "    else:\n",
    "        return 'unclassified'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf129c",
   "metadata": {},
   "source": [
    "## Initial test of our filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c758345",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_test['sms_message'] = initial_test['sms_message'].str.replace('\\W', ' ', regex=True).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e33c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectorized, vocabulary = vectorize(initial_training)\n",
    "p_spam, p_ham, cond_spam, cond_ham = get_probs(train_vectorized, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced8e27",
   "metadata": {},
   "source": [
    "Let's check a couple of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fd3dafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS: \"later i guess  i needa do mcat study too \"\n",
      "P(Spam|SMS) = 2.358527594972535e-30\n",
      "P(Ham|SMS) = 1.3859954358708115e-23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(initial_test['sms_message'][0], p_spam, p_ham, cond_spam, cond_ham, print_posterior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "425d1204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS: \"had your mobile 10 mths  update to latest orange camera video phones for free  save  s with free texts weekend calls  text yes for a callback orno to opt out\"\n",
      "P(Spam|SMS) = 4.026633211507193e-100\n",
      "P(Ham|SMS) = 1.118169555940427e-116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(initial_test['sms_message'][2], p_spam, p_ham, cond_spam, cond_ham, print_posterior=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c617988",
   "metadata": {},
   "source": [
    "It seems to be working. Let's see the general accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b43823f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = initial_test['sms_message'].apply(\n",
    "    lambda s: classify(s, p_spam, p_ham, cond_spam, cond_ham)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efb6cb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1098\n",
       "False      16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == initial_test['is_spam']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12d850ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.985637\n",
       "False    0.014363\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == initial_test['is_spam']).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0348727c",
   "metadata": {},
   "source": [
    "The results look very good on our inital test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b78d2",
   "metadata": {},
   "source": [
    "## Cross-validation on our filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a071f62",
   "metadata": {},
   "source": [
    "Now we'll proceed with cross-validaton. First we'll take a look at the distribution of the target on training and test sets on each iteration to check whether they are similar to the whole data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aebd1610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target on iteration 0\n",
      "Training set:\n",
      "0    0.86538\n",
      "1    0.13462\n",
      "Name: is_spam, dtype: float64\n",
      "Test set:\n",
      "0    0.868161\n",
      "1    0.131839\n",
      "Name: is_spam, dtype: float64\n",
      "\n",
      "Distribution of target on iteration 1\n",
      "Training set:\n",
      "0    0.868521\n",
      "1    0.131479\n",
      "Name: is_spam, dtype: float64\n",
      "Test set:\n",
      "0    0.855605\n",
      "1    0.144395\n",
      "Name: is_spam, dtype: float64\n",
      "\n",
      "Distribution of target on iteration 2\n",
      "Training set:\n",
      "0    0.866981\n",
      "1    0.133019\n",
      "Name: is_spam, dtype: float64\n",
      "Test set:\n",
      "0    0.861759\n",
      "1    0.138241\n",
      "Name: is_spam, dtype: float64\n",
      "\n",
      "Distribution of target on iteration 3\n",
      "Training set:\n",
      "0    0.863392\n",
      "1    0.136608\n",
      "Name: is_spam, dtype: float64\n",
      "Test set:\n",
      "0    0.876122\n",
      "1    0.123878\n",
      "Name: is_spam, dtype: float64\n",
      "\n",
      "Distribution of target on iteration 4\n",
      "Training set:\n",
      "0    0.86541\n",
      "1    0.13459\n",
      "Name: is_spam, dtype: float64\n",
      "Test set:\n",
      "0    0.868043\n",
      "1    0.131957\n",
      "Name: is_spam, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for i, (tr, tt) in enumerate(cv.split(sms)):\n",
    "    print(f\"Distribution of target on iteration {i}\")\n",
    "    print(\"Training set:\")\n",
    "    print(sms['is_spam'].iloc[tr].value_counts(normalize=True))\n",
    "    print(\"Test set:\")\n",
    "    print(sms['is_spam'].iloc[tt].value_counts(normalize=True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30bbaf6",
   "metadata": {},
   "source": [
    "We'll keep records for each model in a separate dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ef9c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0878079e",
   "metadata": {},
   "source": [
    "Note that the output of `get_probs` is the same for each iteration of `cv`, so we want to run it only once for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "728aaedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     1101\n",
      "False      14\n",
      "dtype: int64\n",
      "True     1092\n",
      "False      23\n",
      "dtype: int64\n",
      "True     1099\n",
      "False      15\n",
      "dtype: int64\n",
      "True     1100\n",
      "False      14\n",
      "dtype: int64\n",
      "True     1098\n",
      "False      16\n",
      "dtype: int64\n",
      "\n",
      "accuracies: [0.9874439461883409, 0.979372197309417, 0.9865350089766607, 0.9874326750448833, 0.9856373429084381]\n",
      "mean accuracy: 0.985284234085548\n",
      "standard deviation: 0.0030305595996140775\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "for i, (tr, tt) in enumerate(cv.split(sms)):\n",
    "    train =  sms.iloc[tr].reset_index(drop=True)\n",
    "    test = sms.iloc[tt].reset_index(drop=True)\n",
    "\n",
    "    test['sms_message'] = test['sms_message'].str.replace('\\W', ' ', regex=True).str.lower()\n",
    "\n",
    "    train_vectorized, vocabulary = vectorize(train)\n",
    "    p_spam, p_ham, cond_spam, cond_ham = get_probs(train_vectorized, vocabulary)\n",
    "    \n",
    "    preds = test['sms_message'].apply(\n",
    "        lambda sms: classify(sms, p_spam, p_ham, cond_spam, cond_ham)\n",
    "    )\n",
    "\n",
    "    mask = (preds == test['is_spam'])\n",
    "    print(mask.value_counts())\n",
    "\n",
    "    accuracies.append(mask.value_counts(normalize=True)[True])\n",
    "\n",
    "print()\n",
    "print(f\"accuracies: {accuracies}\")\n",
    "print(f\"mean accuracy: {np.mean(accuracies)}\")\n",
    "print(f\"standard deviation: {np.std(accuracies)}\")\n",
    "\n",
    "results['our_filter'] = [np.mean(accuracies), np.std(accuracies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d768fa4",
   "metadata": {},
   "source": [
    "## Models from `scikit-learn`\n",
    "\n",
    "Now we move on to try a few models from `scikit-learn` on our data set. We will use the same `cv` splits we used above on all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f65c80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model):\n",
    "    accuracies = []\n",
    "\n",
    "    for i, (tr, tt) in enumerate(cv.split(sms)):\n",
    "        cvec = CountVectorizer(ngram_range=(1, 2), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "        train_vectorized = cvec.fit_transform(sms.iloc[tr]['sms_message'])\n",
    "        test_vectorized = cvec.transform(sms.iloc[tt]['sms_message'])\n",
    "\n",
    "        model.fit(train_vectorized, sms.iloc[tr]['is_spam'])\n",
    "        preds = model.predict(test_vectorized)\n",
    "\n",
    "        mask = (preds == sms.iloc[tt]['is_spam'])\n",
    "        print(mask.value_counts())\n",
    "\n",
    "        accuracies.append(mask.value_counts(normalize=True)[True])\n",
    "    \n",
    "    print()\n",
    "    print(f\"accuracies: {accuracies}\")\n",
    "    print(f\"mean accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"standard deviation: {np.std(accuracies)}\")\n",
    "\n",
    "    results[str(model)] = [np.mean(accuracies), np.std(accuracies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71fbb20",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d246488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     1105\n",
      "False      10\n",
      "Name: is_spam, dtype: int64\n",
      "True     1097\n",
      "False      18\n",
      "Name: is_spam, dtype: int64\n",
      "True     1098\n",
      "False      16\n",
      "Name: is_spam, dtype: int64\n",
      "True     1101\n",
      "False      13\n",
      "Name: is_spam, dtype: int64\n",
      "True     1101\n",
      "False      13\n",
      "Name: is_spam, dtype: int64\n",
      "\n",
      "accuracies: [0.9910313901345291, 0.9838565022421525, 0.9856373429084381, 0.9883303411131059, 0.9883303411131059]\n",
      "mean accuracy: 0.9874371835022664\n",
      "standard deviation: 0.0024728318503580344\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1) # Laplace smoothing as before\n",
    "\n",
    "get_scores(mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d0a01",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "729a4833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     1088\n",
      "False      27\n",
      "Name: is_spam, dtype: int64\n",
      "True     1080\n",
      "False      35\n",
      "Name: is_spam, dtype: int64\n",
      "True     1078\n",
      "False      36\n",
      "Name: is_spam, dtype: int64\n",
      "True     1080\n",
      "False      34\n",
      "Name: is_spam, dtype: int64\n",
      "True     1088\n",
      "False      26\n",
      "Name: is_spam, dtype: int64\n",
      "\n",
      "accuracies: [0.9757847533632287, 0.968609865470852, 0.9676840215439856, 0.9694793536804309, 0.9766606822262118]\n",
      "mean accuracy: 0.9716437352569418\n",
      "standard deviation: 0.003791728735691018\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "get_scores(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed538c9b",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93ec4341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     1104\n",
      "False      11\n",
      "Name: is_spam, dtype: int64\n",
      "True     1090\n",
      "False      25\n",
      "Name: is_spam, dtype: int64\n",
      "True     1095\n",
      "False      19\n",
      "Name: is_spam, dtype: int64\n",
      "True     1095\n",
      "False      19\n",
      "Name: is_spam, dtype: int64\n",
      "True     1096\n",
      "False      18\n",
      "Name: is_spam, dtype: int64\n",
      "\n",
      "accuracies: [0.9901345291479821, 0.9775784753363229, 0.9829443447037702, 0.9829443447037702, 0.9838420107719928]\n",
      "mean accuracy: 0.9834887409327677\n",
      "standard deviation: 0.003995379193758718\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "\n",
    "get_scores(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d753c",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d15fc480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>our_filter</th>\n",
       "      <th>MultinomialNB(alpha=1)</th>\n",
       "      <th>RandomForestClassifier()</th>\n",
       "      <th>SVC()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean accuracy</th>\n",
       "      <td>0.985284</td>\n",
       "      <td>0.987437</td>\n",
       "      <td>0.971644</td>\n",
       "      <td>0.983489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stdev of accuracies</th>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.003995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     our_filter  MultinomialNB(alpha=1)  \\\n",
       "mean accuracy          0.985284                0.987437   \n",
       "stdev of accuracies    0.003031                0.002473   \n",
       "\n",
       "                     RandomForestClassifier()     SVC()  \n",
       "mean accuracy                        0.971644  0.983489  \n",
       "stdev of accuracies                  0.003792  0.003995  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.rename({0:'mean accuracy', 1:'stdev of accuracies'}, axis=0, inplace=True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1dfd57",
   "metadata": {},
   "source": [
    "Among the models we've tried, multinomial naive Bayes algorithm gives the best scores on this data set. We see that the model we've written is a close second to `sklearn`'s multinomial naive Bayes model, with support vector classifier and random forest classifier following as third and fourth best according to accuracy values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
