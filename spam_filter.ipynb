{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "511b2618-9218-4335-a417-8e5379f7f09b",
   "metadata": {},
   "source": [
    "# Building a Spam Filter Using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571f526-1637-4803-9778-bc0acad1a821",
   "metadata": {},
   "source": [
    "Our aim in this project is to build a spam filter for SMS messages using the multinomial naive Bayes classifier. At the end of this project we will have a program that classifies messages as spam or non-spam (ham) with an accuracy greater than 98%.\n",
    "\n",
    "We are going to use a data set that contains 5,572 SMS messages that are already classified. The data set we will use, and more info on it, can be found on [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c468ba7-543c-4d87-9403-240435fa09ca",
   "metadata": {},
   "source": [
    "## Exploring the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef16b9ee-5cd6-47ec-ae62-c959bfa9c476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f3bff5-fe6e-478a-b273-3bc28151b729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms_label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sms_label                                        sms_message\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name the columns in a way that will not get mixed up with any actual words from messages later on\n",
    "sms = pd.read_csv('files/SMSSpamCollection', sep='\\t', header=None, names=['sms_label', 'sms_message'])\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b418e61-2faf-468b-99c4-45e41cb2d0e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d52de8-0371-4062-9d7e-30881f1864f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: sms_label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['sms_label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de498d-f771-4f2c-a19c-3e45e705f5da",
   "metadata": {},
   "source": [
    "We see that about 87% of the messages in the data set are ham and the remaining are spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f3c5e-a025-46f2-80e3-69367d23a73f",
   "metadata": {},
   "source": [
    "## Forming Training and Test Sets\n",
    "\n",
    "We will split the data set into a training set and a test set, where the training set will have 80% of the data and the rest will be kept as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e2cbf1-0dee-4384-8bce-66baa46bdc5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# The index for splitting\n",
    "cutoff = round(len(sms) * 0.8)\n",
    "\n",
    "# Randomize the data set before splitting\n",
    "sms_randomized = sms.sample(frac=1, random_state=1)\n",
    "\n",
    "training = sms_randomized[:cutoff].reset_index(drop=True)\n",
    "test = sms_randomized[cutoff:].reset_index(drop=True)\n",
    "\n",
    "print(training.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90319f3-eafe-45df-a43d-c196f1b3ed16",
   "metadata": {},
   "source": [
    "Below we take a look at the percentages of spam and ham messages in both sets to check if they are close to the percentage in the full data set; we find that the results are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e03fa2-3af6-4748-8084-1158a29c7fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.86541\n",
       "spam    0.13459\n",
       "Name: sms_label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['sms_label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e50f49c8-c55e-40f5-82ef-5341f20a2da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.868043\n",
       "spam    0.131957\n",
       "Name: sms_label, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['sms_label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb883e-bb74-4170-b110-afc2b5842ade",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "\n",
    "In order to calculate the probabilities used by the multinomial naive Bayes classifier, we first need to encode the messages in a format that makes it easy to extract information. We will form a vocabulary set for the messages in the training set, and we will create a column for each word in the vocabulary that keeps track of how many times the word appears in a message (note that each row corresponds to a message in our data set).\n",
    "\n",
    "First we remove punctuation and change the letters to lower case in all messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e2153ac-9bd0-4301-8240-7ad371bce46d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms_label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sms_label                                        sms_message\n",
       "0       ham                       yep  by the pretty sculpture\n",
       "1       ham      yes  princess  are you going to make me moan \n",
       "2       ham                         welp apparently he retired\n",
       "3       ham                                            havent \n",
       "4       ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['sms_message'] = training['sms_message'].str.replace('\\W', ' ', regex=True).str.lower()\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6fd813-3164-4c7d-8f53-c9d4cf7fe0e5",
   "metadata": {},
   "source": [
    "Next we create a vocabulary, that is, a set containing all the unique words appearing in all messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e227718c-9d0b-45ac-8aeb-3bf13c077511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['sms_message'] = training['sms_message'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for message in training['sms_message']:\n",
    "    for word in message:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "# Form a set to remove reccurences\n",
    "vocabulary = list(set(vocabulary))\n",
    "\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa73f49c-2e1e-416b-af9a-6594d231373a",
   "metadata": {},
   "source": [
    "Now we use the vocabulary to add columns to our training set that will trace occurences of each word in each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c7897a6-4c08-41d3-85f2-d918f2ec5394",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fatty</th>\n",
       "      <th>oli</th>\n",
       "      <th>blur</th>\n",
       "      <th>gona</th>\n",
       "      <th>october</th>\n",
       "      <th>hunting</th>\n",
       "      <th>showrooms</th>\n",
       "      <th>cstore</th>\n",
       "      <th>weirdest</th>\n",
       "      <th>enjoying</th>\n",
       "      <th>...</th>\n",
       "      <th>enjoyed</th>\n",
       "      <th>lifetime</th>\n",
       "      <th>tirupur</th>\n",
       "      <th>freezing</th>\n",
       "      <th>tap</th>\n",
       "      <th>oops</th>\n",
       "      <th>server</th>\n",
       "      <th>albi</th>\n",
       "      <th>burgundy</th>\n",
       "      <th>vegas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fatty  oli  blur  gona  october  hunting  showrooms  cstore  weirdest  \\\n",
       "0      0    0     0     0        0        0          0       0         0   \n",
       "1      0    0     0     0        0        0          0       0         0   \n",
       "2      0    0     0     0        0        0          0       0         0   \n",
       "3      0    0     0     0        0        0          0       0         0   \n",
       "4      0    0     0     0        0        0          0       0         0   \n",
       "\n",
       "   enjoying  ...  enjoyed  lifetime  tirupur  freezing  tap  oops  server  \\\n",
       "0         0  ...        0         0        0         0    0     0       0   \n",
       "1         0  ...        0         0        0         0    0     0       0   \n",
       "2         0  ...        0         0        0         0    0     0       0   \n",
       "3         0  ...        0         0        0         0    0     0       0   \n",
       "4         0  ...        0         0        0         0    0     0       0   \n",
       "\n",
       "   albi  burgundy  vegas  \n",
       "0     0         0      0  \n",
       "1     0         0      0  \n",
       "2     0         0      0  \n",
       "3     0         0      0  \n",
       "4     0         0      0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary mapping each word to the number of times it appears in each message\n",
    "word_counts = {word: [0] * len(training) for word in vocabulary}\n",
    "\n",
    "# Go through each message to count\n",
    "for index, message in enumerate(training['sms_message']):\n",
    "    for word in message:\n",
    "        word_counts[word][index] += 1\n",
    "\n",
    "word_counts = pd.DataFrame(word_counts)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dcfed40-300d-4874-9b6b-44c12a8f44ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms_label</th>\n",
       "      <th>sms_message</th>\n",
       "      <th>fatty</th>\n",
       "      <th>oli</th>\n",
       "      <th>blur</th>\n",
       "      <th>gona</th>\n",
       "      <th>october</th>\n",
       "      <th>hunting</th>\n",
       "      <th>showrooms</th>\n",
       "      <th>cstore</th>\n",
       "      <th>...</th>\n",
       "      <th>enjoyed</th>\n",
       "      <th>lifetime</th>\n",
       "      <th>tirupur</th>\n",
       "      <th>freezing</th>\n",
       "      <th>tap</th>\n",
       "      <th>oops</th>\n",
       "      <th>server</th>\n",
       "      <th>albi</th>\n",
       "      <th>burgundy</th>\n",
       "      <th>vegas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sms_label                                        sms_message  fatty  oli  \\\n",
       "0       ham                  [yep, by, the, pretty, sculpture]      0    0   \n",
       "1       ham  [yes, princess, are, you, going, to, make, me,...      0    0   \n",
       "2       ham                    [welp, apparently, he, retired]      0    0   \n",
       "3       ham                                           [havent]      0    0   \n",
       "4       ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...      0    0   \n",
       "\n",
       "   blur  gona  october  hunting  showrooms  cstore  ...  enjoyed  lifetime  \\\n",
       "0     0     0        0        0          0       0  ...        0         0   \n",
       "1     0     0        0        0          0       0  ...        0         0   \n",
       "2     0     0        0        0          0       0  ...        0         0   \n",
       "3     0     0        0        0          0       0  ...        0         0   \n",
       "4     0     0        0        0          0       0  ...        0         0   \n",
       "\n",
       "   tirupur  freezing  tap  oops  server  albi  burgundy  vegas  \n",
       "0        0         0    0     0       0     0         0      0  \n",
       "1        0         0    0     0       0     0         0      0  \n",
       "2        0         0    0     0       0     0         0      0  \n",
       "3        0         0    0     0       0     0         0      0  \n",
       "4        0         0    0     0       0     0         0      0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.concat([training, word_counts], axis=1)\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08138976-2c6c-4733-8c19-b3d0f6e15220",
   "metadata": {},
   "source": [
    "## Using Multinomial Naive Bayes\n",
    "\n",
    "Now that our training set is ready, we will start our calculations needed for the spam filter.\n",
    "\n",
    "Recall that, given a message, the multinomial naive Bayes algorithm uses the following proportions to classify the message:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation*}\n",
    "\n",
    "Here, to calculate $P(w_i|Spam)$ and $P(w_i|Ham)$, we will use Laplace smoothing ($\\alpha = 1$).\n",
    "\n",
    "\\begin{equation*}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbccae6-4c7f-49ca-ab8f-78a986faa7e0",
   "metadata": {},
   "source": [
    "We start by calculating the terms that recur for each word, that is, the ones independent of $w_i$. These are $P(Spam)$, $P(Ham)$, $N_{Spam}$, $N_{Ham}$ and $N_{Vocabulary}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4a5200d-4185-4f32-89a6-13c40bf85730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spam = training[training['sms_label'] == 'spam']\n",
    "ham = training[training['sms_label'] == 'ham']\n",
    "\n",
    "p_spam = len(spam) / len(training)\n",
    "p_ham = len(ham) / len(training)\n",
    "\n",
    "n_spam = spam['sms_message'].apply(len).sum()\n",
    "n_ham = ham['sms_message'].apply(len).sum()\n",
    "\n",
    "n_vocabulary = len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb344f73-fe29-46b8-9bfe-27d0bdaef80c",
   "metadata": {},
   "source": [
    "Next we calculate the conditional probabilities for each word, namely $P(w_i|Spam)$ and $P(w_i|Ham)$. We will use separate dictionaries for the spam and ham cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1d366e-f371-4c7b-b856-4953097d4457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cond_spam, cond_ham = {}, {}\n",
    "\n",
    "alpha = 1\n",
    "\n",
    "for w in vocabulary:\n",
    "    cond_spam[w] = (spam[w].sum() + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    cond_ham[w] = (ham[w].sum() + alpha) / (n_ham + alpha * n_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa3b56-05a5-47c8-99f7-d1f312b27136",
   "metadata": {},
   "source": [
    "Now we are ready to go ahead with the classification. Recall that the classifier compares the products $P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)$ and $P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed99656-509d-4df3-be70-50f425bcb88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(sms, print_posterior=False):\n",
    "    '''sms: (str) an sms message\n",
    "    returns: (str) classification of s\n",
    "    '''\n",
    "    s = re.sub('\\W', ' ', sms)\n",
    "    s = s.lower().split()\n",
    "    \n",
    "    p_spam_given_sms = p_spam\n",
    "    p_ham_given_sms = p_ham\n",
    "    \n",
    "    for w in s:\n",
    "        if w in cond_spam:\n",
    "            p_spam_given_sms *= cond_spam[w]\n",
    "        if w in cond_ham:\n",
    "            p_ham_given_sms *= cond_ham[w]\n",
    "    \n",
    "    if print_posterior:\n",
    "        print(\"SMS: \\\"{}\\\"\".format(sms))\n",
    "        print(\"P(Spam|SMS) = {}\".format(p_spam_given_sms))\n",
    "        print(\"P(Ham|SMS) = {}\".format(p_ham_given_sms))\n",
    "    \n",
    "    if p_spam_given_sms > p_ham_given_sms:\n",
    "        return 'spam'\n",
    "    elif p_spam_given_sms < p_ham_given_sms:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'unclassified'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5ad760-61f9-47e6-add4-aba57e8d5e17",
   "metadata": {},
   "source": [
    "Let's try a couple of messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d0f0a25-4fb5-4cb7-bebc-6fc7c2ca1691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms_label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sms_label                                        sms_message\n",
       "0       ham          Later i guess. I needa do mcat study too.\n",
       "1       ham             But i haf enuff space got like 4 mb...\n",
       "2      spam  Had your mobile 10 mths? Update to latest Oran...\n",
       "3       ham  All sounds good. Fingers . Makes it difficult ...\n",
       "4       ham  All done, all handed in. Don't know if mega sh..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67098e65-63d5-4f9e-9b95-8667c23dbd28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS: \"Later i guess. I needa do mcat study too.\"\n",
      "P(Spam|SMS) = 3.4831070937898343e-26\n",
      "P(Ham|SMS) = 4.253245130534654e-19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(test['sms_message'][0], print_posterior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62b112c4-4929-43f1-83a0-425249c2f50b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS: \"Had your mobile 10 mths? Update to latest Orange camera/video phones for FREE. Save £s with Free texts/weekend calls. Text YES for a callback orno to opt out\"\n",
      "P(Spam|SMS) = 7.548549643070596e-83\n",
      "P(Ham|SMS) = 4.338466063216561e-98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(test['sms_message'][2], print_posterior=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eecee3-984a-4fc4-9977-63262ff9d2ff",
   "metadata": {},
   "source": [
    "## Conclusion: Measuring Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac92e78-14cf-4553-86c6-bf64501e9818",
   "metadata": {},
   "source": [
    "Now that we have built our spam filter, we will see how it performs on the test set. We will create a new column containing the output of our classifier, and then compare it with the original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "245b2812-31b8-4cbe-9bf1-e48aaaf6bce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms_label</th>\n",
       "      <th>sms_message</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sms_label                                        sms_message prediction\n",
       "0       ham          Later i guess. I needa do mcat study too.        ham\n",
       "1       ham             But i haf enuff space got like 4 mb...        ham\n",
       "2      spam  Had your mobile 10 mths? Update to latest Oran...       spam\n",
       "3       ham  All sounds good. Fingers . Makes it difficult ...        ham\n",
       "4       ham  All done, all handed in. Don't know if mega sh...        ham"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['prediction'] = test['sms_message'].apply(classify)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2d83ab9-9709-4368-9ba9-701bbcb67df0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1100\n",
       "False      14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = test['sms_label'] == test['prediction']\n",
    "correct.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13a5633c-d91d-4e2c-8fc5-d9db1edaea51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.987433\n",
       "False    0.012567\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7339f24c-bf00-4caa-adf7-c2dea99afa2b",
   "metadata": {},
   "source": [
    "The accuracy of our spam filter is close to 98.74%. Out of the 1114 messages in the test set, our filter misclassified only 14."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
